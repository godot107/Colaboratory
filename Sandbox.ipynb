{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sandbox.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2BhINGYtyxRowK9RRfNne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/godot107/Colaboratory/blob/main/Sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiwembnB2wTL"
      },
      "source": [
        "Training a Binary Classifier\r\n",
        "Source: Machine Learning with Python Cookbook_ Practical Solutions from Preprocessing to Deep Learning\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFUT6PJC1Lgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3facc52-0973-4898-c966-bdebd7ab2812"
      },
      "source": [
        "# Load libraries\r\n",
        "import numpy as np\r\n",
        "from keras.datasets import imdb\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "# Set random seed\r\n",
        "np.random.seed(0)\r\n",
        "# Set the number of features we want\r\n",
        "number_of_features = 1000\r\n",
        "# Load data and target vector from movie review data\r\n",
        "(data_train, target_train), (data_test, target_test) = imdb.load_data(\r\n",
        "num_words=number_of_features)\r\n",
        "# Convert movie review data to one-hot encoded feature matrix\r\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\r\n",
        "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\r\n",
        "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\r\n",
        "# Start neural network\r\n",
        "network = models.Sequential()\r\n",
        "# Add fully connected layer with a ReLU activation function\r\n",
        "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(\r\n",
        "number_of_features,)))\r\n",
        "# Add fully connected layer with a ReLU activation function\r\n",
        "network.add(layers.Dense(units=16, activation=\"relu\"))\r\n",
        "# Add fully connected layer with a sigmoid activation function\r\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\r\n",
        "# Compile neural network\r\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\r\n",
        "optimizer=\"rmsprop\", # Root Mean Square Propagation\r\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\r\n",
        "\r\n",
        "# Train neural network\r\n",
        "history = network.fit(features_train, # Features\r\n",
        "target_train, # Target vector\r\n",
        "epochs=3, # Number of epochs\r\n",
        "verbose=1, # Print description after each epoch\r\n",
        "batch_size=100, # Number of observations per batch\r\n",
        "validation_data=(features_test, target_test)) # Test data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "250/250 [==============================] - 2s 5ms/step - loss: 0.4993 - accuracy: 0.7615 - val_loss: 0.3427 - val_accuracy: 0.8541\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.8633 - val_loss: 0.3268 - val_accuracy: 0.8618\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3108 - accuracy: 0.8714 - val_loss: 0.3278 - val_accuracy: 0.8601\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}